---
title: "Report on SINDy progress"
author: "Gage Bonner and Michael Castellucci"
latex-tinytex: true
format:
  pdf:
    documentclass: article
    # classoption: [twocolumn]
    keep-tex: true
    toc: true
    number-sections: true
    colorlinks: true
    include-in-header:
      - text: |
          \usepackage{algorithm}
          \usepackage{algpseudocode}
          \usepackage[left=2cm,right=2cm,top = 2cm,bottom = 2cm]{geometry}
          \usepackage[style=alphabetic]{biblatex}
    cite-method: biblatex
# format:
#   html:
#     toc: true
#     html-math-method: mathml
bibliography: refs.bib
engine: julia
julia:
  exeflags: ["--project=/Users/gagebonner/Desktop/Repositories/SINDy-Implementation/"]
highlight-style: arrow
---

***

```{julia}
#| output: false
#| echo: false
include(joinpath(@__DIR__, "..", "sindy2.jl"))
using CairoMakie; set_theme!(theme_latexfonts())
```

# Summary of work

In this project, we investigated the application of *data discovery* algorithms to learn the governing equations for a dynamical system from numerical realizations of their trajectories. We apply the sparse identification of nonlinear dynamics (``SINDy") as originally proposed in \cite{brunton2016discovering} as well as a number of its extensions. The core idea behind these algorithms is that many dynamical systems in science are represented by differential equation systems $\dot{x} = f(x)$ where $f(x)$ often a linear combination of a small number of elementary functions. By contrast, the trajectories $x(t)$ may be extremely complicated and ill-suited to direct fitting. Consider the classic Lorenz system
\begin{subequations} \label{eq:lorenz-def}
\begin{align} 
    \dot{x} &= 10 (y - x), \\
    \dot{y} &= x (28 - z) - y, \\ 
    \dot{z} &= x y - (8 / 3) z .
\end{align}
\end{subequations}
Trajectories $X(t) = (x(t), y(t), z(t))$ of this system are chaotic, making it difficult or impossible to propose a function that fits $X(t)$ directly. On the other hand, $\dot{X}$ is a low order polynomial function of $X(t)$ and hence should be much more tractable in principle. At the highest level, we therefore have the following problem: given numerical trajectories $\{x(t_1), x(t_2), \dots \}$, compute numerically $\{\dot{x}(t_1), \dot{x}(t_2), \dots \}$ and attempt to find a parsimonious (equivalently: \emph{sparse}) combination of simple functions of the $x(t)$ that faithfully represents it. 

This report contains embedded code from the [Julia](https://julialang.org/) programming language.

# Core algorithms

## Sparse representations

Suppose that several values of a function of $f : \mathbb{R} \to \mathbb{R}$ are observed, $\{f(x_1), f(x_2), \dots \}$. A \emph{sparse representation} seeks to represent $f$ as a linear combination of elementary functions of $x$ that contains as few terms as possible while still faithfully representing the behavior of $f$. As a first example, take $f(x) = x + \sin(x)$. We will add a small noise term to simulate real data. This is shown in Figure \ref{fig:f-1}.

```{julia}
#| output: false
f_simple_1(x) = x + sin(x)
x_points_1 = range(-5, 5, length = 20) |> collect
f_points_1 = [f_simple_1(x) + 0.2*rand() for x in x_points_1]
```

```{julia}
#| output: false
#| echo: false
let
fig = Figure(fontsize = 25)
ax = Axis(fig[1, 1], xlabel = L"x", ylabel = L"f(x) = x + \sin(x)", aspect = AxisAspect(1))
scatter!(ax, x_points_1, f_points_1, color = :black,  markersize = 15)
save(joinpath(@__DIR__, "figures", "f-1.png"), fig)
end
```

\begin{figure}
    \centering
    \includegraphics[width = 0.5\textwidth]{figures/f-1.png}
    \caption{A simple data set from a scalar function.}
    \label{fig:f-1}
\end{figure}

Assuming now that we are given this data with no knowledge of the underlying mechanics, how could this function be represented? Due to the oscillatory nature of the function, we might assume that it may be some linear combination of simple polynomials and sinusoids. Provided this sort of "expert knowledge", we could propose a \emph{library} of functions $L(x)$ that constitute the set of all possible functions that we want to include in our model. In our case, we will take our library to be the vector
\begin{equation}
L(x) = (1, x, x^2, x^3, \sin x, \cos x).
\end{equation}
The problem is therefore to find a vector $\xi \in \mathbb{R}^7$ such that $f(x) \approx \xi \cdot L(x)$. To do this, we will construct an optimization problem whose solution is $\xi$ that takes all of our observational data into account. The \emph{library data} $\Theta$ is given by
\begin{equation}
\Theta(x) 
= 
\begin{pmatrix}
L_1(x_1) & L_2(x_1) & \cdots & L_7(x_1) \\ 
L_1(x_2) & L_2(x_2) & \cdots & L_7(x_2) \\
\vdots   & \vdots   & \ddots & \vdots   \\
L_1(x_N) & L_2(x_N) & \cdots & L_7(x_N) 
\end{pmatrix}
=
\begin{pmatrix}
1 & x_1 & \cdots & \cos(x_1) \\ 
1 & x_2 & \cdots & \cos(x_2) \\
\vdots   & \vdots   & \ddots & \vdots   \\
1 & x_N & \cdots & \cos(x_N) 
\end{pmatrix}.
\end{equation}
Given our \emph{target data} $F = (f(x_1), f(x_2), \dots)$, we naturally have the following optimization problem
\begin{equation}
\xi^\star = \underset{\xi \in \mathbb{R}^7}{\text{argmin}} \lVert F - \Theta \xi \rVert_{2} ,
\end{equation}
where $\Vert\cdot\rVert_2$ indicates the $L_2$ norm and where our final representation is $f(x) \approx L(x) \cdot \xi^\star$. This kind of simple problem is directly amenable to a linear least-squares solution.

```{julia}
#| output: false
library_1 = [x -> 1.0, x -> x, x -> x^2, x -> x^3, x -> sin(x), x -> cos(x)]
library_names_1 = ["1", "x", "x^2", "x^3", "sin(x)", "cos(x)"]
library_data_1 = [f(t) for t in x_points_1, f in library_1]

ls_1 = MultivariateStats.llsq(library_data_1, f_points_1, bias = false)
f_llsq_1(x) = sum(ls_1[i]*library_1[i](x) for i = 1:length(ls_1))
```

```{julia}
#| echo: false
let
pp_ls = pretty_print(ls_1, library_names_1)

md"""
\begin{equation} \label{eq:f-simple-1-sparse}
  f\_{\text{llsq}}(x) = $(latexify(pp_ls, env = :raw, fmt  = FancyNumberFormatter(3)))
\end{equation}
"""
end
```

We can see that the fit produced is indeed quite good as in Figure \ref{fig:f-simple-llsq}.

```{julia}
#| output: false
#| echo: false
let
x = x_points_1
f = [f_llsq_1(x) for x in x_points_1]

fig = Figure(fontsize = 25)
ax = Axis(fig[1, 1], xlabel = L"x", ylabel = L"f", aspect = AxisAspect(1))
scatter!(ax, x_points_1, f_points_1, color = :black, markersize = 15, label = L"f(x)")
lines!(ax, x, f, color = :red,  linewidth = 4, label = L"f_{\text{llsq}}(x)")
axislegend(ax, position = :lt)
save(joinpath(@__DIR__, "figures", "f-1-llsq.png"), fig)
end
```

\begin{figure}
    \centering
    \includegraphics[width = 0.5\textwidth]{figures/f-1-llsq.png}
    \caption{The linear least squares result.}
    \label{fig:f-simple-llsq}
\end{figure}

However, $f_{\text{llsq}}$ is not sparse, that is, it contains more terms than it necessarily needs to and, in particular, many terms that have small coefficients. 

\clearpage

```{julia}
# let
times = x_points_1 |> collect
target_data = f_points_1

library = [x -> 1.0, x -> x, x -> x^2, x -> x^3, x -> sin(x), x -> cos(x)]
library_names = ["1", "x", "x^2", "x^3", "sin(x)", "cos(x)"]
library_data = [f(t) for t in times, f in library]

λ_sparse = 0.5
λ_ridge = 0.1

ls = MultivariateStats.llsq(library_data, target_data, bias = false)
pp_ls = pretty_print(ls, library_names)

rr = MultivariateStats.ridge(library_data, target_data, λ_ridge, bias = false)
pp_rr = pretty_print(rr, library_names)

sr = sparse_representation(times, target_data, library_data, λ_sparse = λ_sparse, λ_ridge = λ_ridge)
pp_sr = pretty_print(sr, library_names)

md"""
\begin{subequations} \label{eq:f-simple-1-sparse}
\begin{align} 
  \mathrm{llsq} &= $(latexify(pp_ls, env = :raw, fmt  = FancyNumberFormatter(3))) \\\\
  \mathrm{ridge} &= $(latexify(pp_rr, env = :raw, fmt  = FancyNumberFormatter(3))) \\\\
  \mathrm{sparse} &= $(latexify(pp_sr, env = :raw, fmt  = FancyNumberFormatter(3)))
\end{align}
\end{subequations}
"""
# end
```

As a first example, take $f(x) = x + \sin(x) + \cos(x)^2$. We will add a small noise term to simulate real data.

```{julia}
#| output: false
f_simple(x) = x + sin(x) + cos(x)^2
x_points = range(-5, 5, length = 100)
f_points = [f_simple(x) + 0.2*rand() for x in x_points]
```



- Library functions
- need ridge regression since not positive definite

```{julia}
#| output: false
#| echo: false
let
fig = Figure(fontsize = 25)
ax = Axis(fig[1, 1], xlabel = L"x", ylabel = L"f(x) = x + \sin(x) + \cos(x)^2", aspect = AxisAspect(1))
scatter!(ax, x_points, f_points, color = :black,  markersize = 15)
save(joinpath(@__DIR__, "figures", "test.png"), fig)
end
```

\begin{figure}
    \centering
    \includegraphics[width = 0.5\textwidth]{figures/test.png}
    \caption{test}
    \label{fig:test}
\end{figure}

```{julia}
let
times = x_points |> collect
target_data = f_points

library = [x -> 1.0, x -> x, x -> x^2, x -> x^3, x -> sin(x), x -> cos(x)]
library_names = ["1", "x", "x^2", "x^3", "sin(x)", "cos(x)"]
library_data = [f(t) for t in times, f in library]

λ_sparse = 0.5
λ_ridge = 0.1

rr = MultivariateStats.ridge(library_data, target_data, λ_ridge, bias = false)
# @info pretty_print(rr, library_names)

sr = sparse_representation(times, target_data, library_data, λ_sparse = λ_sparse, λ_ridge = λ_ridge)
pp = pretty_print(sr, library_names)

md"""
\begin{equation}
$(latexify(pp, env = :raw))
\end{equation}
"""
end
```


## SINDy

## E-SINDy

# Julia Implementation

# Results

## Direct sparse representations

## Fluid

## Slow

## Full

# Conclusions


```{julia}
1 + 2
```

```{julia}
1 + 2
```


<!-- ```{julia}
f0(t) = 1.0
f1(t) = 2*t
f2(t) = sin(t)
f3(t) = f1(t)*f2(t)
f4(t) = cos(t)
f5(t) = f1(t)*f4(t)

times = range(0.0, 10.0, length = 100) |> collect
target_data1 = [f1(t) + 2*f2(t) - 3*f3(t) + 0.1*rand() for t in times]
target_data2 = [4*f1(t) - 2*f4(t) - 5*f3(t) + 0.1*rand() for t in times]
target_data = [target_data1 ;; target_data2]

library = [f0, f1, f2, t -> f1(t)^1.2, f3, t -> f2(t)^2, f4, f5]
library_names = ["", "2t", "sin(t)", "(2t)^1.2", "2t*sin(t)", "sin(t)^2", "cos(t)", "2t*cos(t)"]
library_data = [f(t) for t in times, f in library]

si = sparse_representation(times, target_data, library_data, library_names = library_names, λ_sparse = 0.1, pretty_print = false)
``` -->


<!-- ```{julia}
function lorenz!(du, u, p, t)
    x, y, z = u
    du[1] = 10.0 * (y - x)
    du[2] = x * (28.0 - z) - y
    du[3] = x * y - (8 / 3) * z
end

prob_vec = ODEProblem(lorenz!, [1.0, 1.0, 1.0], (0.0, 10.0))
sol_vec = solve(prob_vec)
``` -->

Blah blah $sdfadf$
\begin{equation}
F = ma
\end{equation}

::: {.callout-tip icon=false}
## Algorithm 1 (stock)

```{julia}
penguins = 1 # <1>
penguins*2 # <2>
```
1. Take `penguins`, and then,
2. add new columns for the bill ratio and bill area...
:::


\begin{algorithm}
\caption{An algorithm with caption}\label{alg:cap}
\begin{algorithmic}
\Require $n \geq 0$
\Ensure $y = x^n$
\State $y \gets 1$
\State $X \gets x$
\State $N \gets n$
\While{$N \neq 0$}
\If{$N$ is even}
    \State $X \gets X \times X$
    \State $N \gets \frac{N}{2}$  \Comment{This is a comment}
\ElsIf{$N$ is odd}
    \State $y \gets y \times X$
    \State $N \gets N - 1$
\EndIf
\EndWhile
\end{algorithmic}
\end{algorithm}