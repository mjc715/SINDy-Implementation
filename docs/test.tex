% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
]{article}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage[ruled,vlined]{algorithm2e}
\usepackage[left=2cm,right=2cm,top = 2cm,bottom = 2cm]{geometry}
\usepackage[style=alphabetic]{biblatex}
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\definecolor{quarto-callout-color}{HTML}{909090}
\definecolor{quarto-callout-note-color}{HTML}{0758E5}
\definecolor{quarto-callout-important-color}{HTML}{CC1914}
\definecolor{quarto-callout-warning-color}{HTML}{EB9113}
\definecolor{quarto-callout-tip-color}{HTML}{00A047}
\definecolor{quarto-callout-caution-color}{HTML}{FC5300}
\definecolor{quarto-callout-color-frame}{HTML}{acacac}
\definecolor{quarto-callout-note-color-frame}{HTML}{4582ec}
\definecolor{quarto-callout-important-color-frame}{HTML}{d9534f}
\definecolor{quarto-callout-warning-color-frame}{HTML}{f0ad4e}
\definecolor{quarto-callout-tip-color-frame}{HTML}{02b875}
\definecolor{quarto-callout-caution-color-frame}{HTML}{fd7e14}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tikz}{}{\usepackage{tikz}}
\makeatother
        \newcommand*\circled[1]{\tikz[baseline=(char.base)]{
          \node[shape=circle,draw,inner sep=1pt] (char) {{\scriptsize#1}};}}  
                  
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{biblatex}
\addbibresource{refs.bib}
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Report on SINDy progress},
  pdfauthor={Gage Bonner and Michael Castellucci},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Report on SINDy progress}
\author{Gage Bonner and Michael Castellucci}
\date{}

\begin{document}
\maketitle

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{3}
\tableofcontents
}
\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Summary of work}\label{summary-of-work}

In this project, we investigated the application of \emph{data
discovery} algorithms to learn the governing equations for a dynamical
system from numerical realizations of their trajectories. We apply the
sparse identification of nonlinear dynamics (``SINDy'') as originally
proposed in \cite{brunton2016discovering} as well as a number of its
extensions. The core idea behind these algorithms is that many dynamical
systems in science are represented by differential equation systems
\(\dot{x} = f(x)\) where \(f(x)\) is often a linear combination of a
small number of elementary functions. By contrast, the trajectories
\(x(t)\) may be extremely complicated and ill-suited to direct fitting.
Consider the classic Lorenz system
\begin{subequations} \label{eq:lorenz-def}
\begin{align} 
    \dot{x} &= 10 (y - x), \\
    \dot{y} &= x (28 - z) - y, \\ 
    \dot{z} &= x y - (8 / 3) z .
\end{align}
\end{subequations} Trajectories \(X(t) = (x(t), y(t), z(t))\) of this
system are chaotic, making it difficult to fit \(X(t)\) directly. Such a
fit can be obtained by spline interpolation, but this generally reveals
little about the underlying dynamics. On the other hand, \(\dot{X}\) is
a low order polynomial function of \(X(t)\) and hence should be much
more tractable in principle. At the highest level, we therefore have the
following problem: given numerical trajectories
\(\{x(t_1), x(t_2), \dots \}\), compute numerically
\(\{\dot{x}(t_1), \dot{x}(t_2), \dots \}\) and attempt to find a
parsimonious (equivalently: \emph{sparse}) combination of simple
functions of the \(x(t)\) that faithfully represents it.

This report contains embedded code from the
\href{https://julialang.org/}{Julia} programming language.

\section{Core algorithms}\label{core-algorithms}

\subsection{Sparse representations}\label{sparse-representations}

Suppose that several values of a function of
\(f : \mathbb{R} \to \mathbb{R}\) are observed,
\(\{f(x_1), f(x_2), \dots \}\). A \emph{sparse representation} seeks to
represent \(f\) as a linear combination of elementary functions of \(x\)
that contains as few terms as possible while still faithfully
representing the behavior of \(f\). As a first example, take
\(f(x) = x + \sin(x)\). We will add a small noise term to simulate real
data. This is shown in Figure \ref{fig:f-llsq}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{seed!}\NormalTok{(}\FloatTok{1234}\NormalTok{)}
\FunctionTok{f\_simple}\NormalTok{(x) }\OperatorTok{=}\NormalTok{ x }\OperatorTok{+} \FunctionTok{sin}\NormalTok{(x)}
\NormalTok{x\_points\_f\_simple }\OperatorTok{=} \FunctionTok{range}\NormalTok{(}\OperatorTok{{-}}\FloatTok{5}\NormalTok{, }\FloatTok{5}\NormalTok{, length }\OperatorTok{=} \FloatTok{20}\NormalTok{) }\OperatorTok{|\textgreater{}}\NormalTok{ collect}
\NormalTok{f\_simple\_points }\OperatorTok{=}\NormalTok{ [}\FunctionTok{f\_simple}\NormalTok{(x) }\OperatorTok{+} \FloatTok{0.2}\FunctionTok{*rand}\NormalTok{() for x }\KeywordTok{in}\NormalTok{ x\_points\_f\_simple]}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\begin{subfigure}{0.49\textwidth}
    \includegraphics{figures/f-llsq.png}
    \caption{The function $f(x) = x + \sin(x) + \text{noise}$ and the linear least-squares fit $f_\text{llsq}(x)$ of Eq. \eqref{eq:f-1-llsq}.}
    \label{fig:f-llsq}
\end{subfigure}
\hfill
\begin{subfigure}{0.49\textwidth}
    \includegraphics{figures/g-ridge.png}
    \caption{The function $g(x) = x + \sin(x) + \cos^2(x) + \text{noise}$ and the ridge regression fit $g_\text{ridge}(x)$ of Eq. \eqref{eq:g-ridge}.}
    \label{fig:g-ridge}
\end{subfigure}
        
\caption{Fitting of two simple functions using linear least-squares and ridge regression.}
\label{fig:sparse-motivation}
\end{figure}

Assuming now that we are given this data with no knowledge of the
underlying mechanics, how could this function be represented? Due to the
oscillatory nature of the function, we might assume that it may be some
linear combination of simple polynomials and sinusoids. Provided this
sort of ``expert knowledge'', we could propose a \emph{library} of
functions \(L(x)\) that constitute the set of all possible functions
that we want to include in our model. In our case, we will take our
library to be the vector \begin{equation}
L(x) = (1, x, x^2, x^3, \sin x, \cos x).
\end{equation} The problem is therefore to find a vector
\(\xi \in \mathbb{R}^7\) such that \(f(x) \approx \xi \cdot L(x)\). To
do this, we will construct an optimization problem whose solution is
\(\xi\) that takes all of our observational data into account. The
\emph{library data} \(\Theta\) is given by \begin{equation}
\Theta(x) 
= 
\begin{pmatrix}
L_1(x_1) & L_2(x_1) & \cdots & L_7(x_1) \\ 
L_1(x_2) & L_2(x_2) & \cdots & L_7(x_2) \\
\vdots   & \vdots   & \ddots & \vdots   \\
L_1(x_N) & L_2(x_N) & \cdots & L_7(x_N) 
\end{pmatrix}
=
\begin{pmatrix}
1 & x_1 & \cdots & \cos(x_1) \\ 
1 & x_2 & \cdots & \cos(x_2) \\
\vdots   & \vdots   & \ddots & \vdots   \\
1 & x_N & \cdots & \cos(x_N) 
\end{pmatrix}.
\end{equation} Given our \emph{target data}
\(F = (f(x_1), f(x_2), \dots)\), we naturally have the following
optimization problem \begin{equation}
\xi^\star = \underset{\xi \in \mathbb{R}^7}{\text{argmin}} \lVert F - \Theta \xi \rVert_{2} ,
\end{equation} where \(\Vert\cdot\rVert_2\) indicates the \(L_2\) norm
and where our final representation is
\(f(x) \approx L(x) \cdot \xi^\star\). This kind of simple problem is
directly amenable to a linear least-squares solution.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{library }\OperatorTok{=}\NormalTok{ [x }\OperatorTok{{-}\textgreater{}} \FloatTok{1.0}\NormalTok{, x }\OperatorTok{{-}\textgreater{}}\NormalTok{ x, x }\OperatorTok{{-}\textgreater{}}\NormalTok{ x}\OperatorTok{\^{}}\FloatTok{2}\NormalTok{, x }\OperatorTok{{-}\textgreater{}}\NormalTok{ x}\OperatorTok{\^{}}\FloatTok{3}\NormalTok{, x }\OperatorTok{{-}\textgreater{}} \FunctionTok{sin}\NormalTok{(x), x }\OperatorTok{{-}\textgreater{}} \FunctionTok{cos}\NormalTok{(x)]}
\NormalTok{library\_names }\OperatorTok{=}\NormalTok{ [}\StringTok{"1"}\NormalTok{, }\StringTok{"x"}\NormalTok{, }\StringTok{"x\^{}2"}\NormalTok{, }\StringTok{"x\^{}3"}\NormalTok{, }\StringTok{"sin(x)"}\NormalTok{, }\StringTok{"cos(x)"}\NormalTok{]}
\NormalTok{library\_data }\OperatorTok{=}\NormalTok{ [}\FunctionTok{f}\NormalTok{(t) for t }\KeywordTok{in}\NormalTok{ x\_points\_f\_simple, f }\KeywordTok{in}\NormalTok{ library]}

\NormalTok{ls }\OperatorTok{=} \FunctionTok{llsq}\NormalTok{(library\_data, f\_simple\_points, bias }\OperatorTok{=} \ConstantTok{false}\NormalTok{) }\CommentTok{\# from MultivariateStats.jl}
\FunctionTok{f\_llsq\_1}\NormalTok{(x) }\OperatorTok{=} \FunctionTok{sum}\NormalTok{(ls[i]}\OperatorTok{*}\NormalTok{library[i](x) }\ControlFlowTok{for}\NormalTok{ i }\OperatorTok{=} \FloatTok{1}\OperatorTok{:}\FunctionTok{length}\NormalTok{(ls))}

\NormalTok{f\_simple\_pred }\OperatorTok{=}\NormalTok{ library\_data }\OperatorTok{*}\NormalTok{ ls}
\NormalTok{rmse }\OperatorTok{=} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{mean}\NormalTok{(}\FunctionTok{abs2}\NormalTok{.(f\_simple\_points }\OperatorTok{{-}}\NormalTok{ f\_simple\_pred)))}
\end{Highlighting}
\end{Shaded}

\begin{subequations} \label{eq:f-1-llsq} \begin{align}    f_{\text{llsq}}(x) &= 0.111 \cdot 1 + 1.01 \cdot x + 0.000703 \cdot x^{2} -0.000482 \cdot x^{3} + 0.946 \cdot \sin\left( x \right) + 0.000711 \cdot \cos\left( x \right) \\
  \text{RMSE}[f_{\text{llsq}}] &= 0.0421 \end{align} \end{subequations}

We can see that the fit produced is indeed quite good as in Figure
\ref{fig:f-llsq}. However, \(f_{\text{llsq}}\) is not sparse, that is,
it contains more terms than it necessarily needs to and, in particular,
many terms that have small coefficients. Examining Eq.
\eqref{eq:f-1-llsq}, we see that the coefficient of \(x^3\) is very
small. We might therefore try removing it from the library and applying
another linear least-squares fit.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{library }\OperatorTok{=}\NormalTok{ [x }\OperatorTok{{-}\textgreater{}} \FloatTok{1.0}\NormalTok{, x }\OperatorTok{{-}\textgreater{}}\NormalTok{ x, x }\OperatorTok{{-}\textgreater{}}\NormalTok{ x}\OperatorTok{\^{}}\FloatTok{2}\NormalTok{, x }\OperatorTok{{-}\textgreater{}} \FunctionTok{sin}\NormalTok{(x), x }\OperatorTok{{-}\textgreater{}} \FunctionTok{cos}\NormalTok{(x)]}
\NormalTok{library\_names }\OperatorTok{=}\NormalTok{ [}\StringTok{"1"}\NormalTok{, }\StringTok{"x"}\NormalTok{, }\StringTok{"x\^{}2"}\NormalTok{, }\StringTok{"sin(x)"}\NormalTok{, }\StringTok{"cos(x)"}\NormalTok{]}
\NormalTok{library\_data }\OperatorTok{=}\NormalTok{ [}\FunctionTok{f}\NormalTok{(t) for t }\KeywordTok{in}\NormalTok{ x\_points\_f\_simple, f }\KeywordTok{in}\NormalTok{ library]}

\NormalTok{ls }\OperatorTok{=} \FunctionTok{llsq}\NormalTok{(library\_data, f\_simple\_points, bias }\OperatorTok{=} \ConstantTok{false}\NormalTok{)}
\FunctionTok{f\_llsq\_2}\NormalTok{(x) }\OperatorTok{=} \FunctionTok{sum}\NormalTok{(ls[i]}\OperatorTok{*}\NormalTok{library[i](x) }\ControlFlowTok{for}\NormalTok{ i }\OperatorTok{=} \FloatTok{1}\OperatorTok{:}\FunctionTok{length}\NormalTok{(ls))}

\NormalTok{f\_simple\_pred }\OperatorTok{=}\NormalTok{ library\_data }\OperatorTok{*}\NormalTok{ ls}
\NormalTok{rmse }\OperatorTok{=} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{mean}\NormalTok{(}\FunctionTok{abs2}\NormalTok{.(f\_simple\_points }\OperatorTok{{-}}\NormalTok{ f\_simple\_pred)))}
\end{Highlighting}
\end{Shaded}

\begin{subequations} \label{eq:f-2-llsq} \begin{align}    f_{\text{llsq, 2}}(x) &= 0.111 \cdot 1 + 1 \cdot x + 0.000703 \cdot x^{2} + 0.958 \cdot \sin\left( x \right) + 0.000711 \cdot \cos\left( x \right) \\
    \text{RMSE}[f_{\text{llsq}}] &= 0.0425 \end{align} \end{subequations}

This has produced a more parsimonious representation and comparing Eqs.
\eqref{eq:f-1-llsq} and \eqref{eq:f-2-llsq} shows that the RSME has
increased by a negligible amount.

This calculation contains the essence of the basic sparse representation
algorithm: iteratively regress library functions onto the target data
and remove small coefficients. Before moving on, we will consider one
more example which demonstrates the need for a more advanced regression
tool than the basic linear least-squares. In this case we will take
\(g(x) = x + \sin(x) + \cos(x)^2\), see Figure \ref{fig:g-ridge}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{seed!}\NormalTok{(}\FloatTok{1234}\NormalTok{)}
\FunctionTok{g\_simple}\NormalTok{(x) }\OperatorTok{=}\NormalTok{ x }\OperatorTok{+} \FunctionTok{sin}\NormalTok{(x) }\OperatorTok{+} \FunctionTok{cos}\NormalTok{(x)}\OperatorTok{\^{}}\FloatTok{2}
\NormalTok{x\_points\_g }\OperatorTok{=} \FunctionTok{range}\NormalTok{(}\OperatorTok{{-}}\FloatTok{5}\NormalTok{, }\FloatTok{5}\NormalTok{, length }\OperatorTok{=} \FloatTok{20}\NormalTok{) }\OperatorTok{|\textgreater{}}\NormalTok{ collect}
\NormalTok{g\_points }\OperatorTok{=}\NormalTok{ [}\FunctionTok{g\_simple}\NormalTok{(x) }\OperatorTok{+} \FloatTok{0.2}\FunctionTok{*rand}\NormalTok{() for x }\KeywordTok{in}\NormalTok{ x\_points\_g]}
\end{Highlighting}
\end{Shaded}

Using expert knowledge of \(g(x)\), we will augment our library with
squared sinusoids. We might attempt the following solution as per the
earlier calculations.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{library }\OperatorTok{=}\NormalTok{ [}
\NormalTok{  x }\OperatorTok{{-}\textgreater{}} \FloatTok{1.0}\NormalTok{, x }\OperatorTok{{-}\textgreater{}}\NormalTok{ x, x }\OperatorTok{{-}\textgreater{}}\NormalTok{ x}\OperatorTok{\^{}}\FloatTok{2}\NormalTok{, x }\OperatorTok{{-}\textgreater{}}\NormalTok{ x}\OperatorTok{\^{}}\FloatTok{3}\NormalTok{, }
\NormalTok{  x }\OperatorTok{{-}\textgreater{}} \FunctionTok{sin}\NormalTok{(x), x }\OperatorTok{{-}\textgreater{}} \FunctionTok{cos}\NormalTok{(x), }
\NormalTok{  x }\OperatorTok{{-}\textgreater{}} \FunctionTok{sin}\NormalTok{(x)}\OperatorTok{\^{}}\FloatTok{2}\NormalTok{, x }\OperatorTok{{-}\textgreater{}} \FunctionTok{cos}\NormalTok{(x)}\OperatorTok{\^{}}\FloatTok{2}\NormalTok{]}
\NormalTok{library\_names }\OperatorTok{=}\NormalTok{ [}\StringTok{"1"}\NormalTok{, }\StringTok{"x"}\NormalTok{, }\StringTok{"x\^{}2"}\NormalTok{, }\StringTok{"x\^{}3"}\NormalTok{, }\StringTok{"sin(x)"}\NormalTok{, }\StringTok{"cos(x)"}\NormalTok{, }\StringTok{"sin(x)\^{}2"}\NormalTok{, }\StringTok{"cos(x)\^{}2"}\NormalTok{]}
\NormalTok{library\_data }\OperatorTok{=}\NormalTok{ [}\FunctionTok{f}\NormalTok{(t) for t }\KeywordTok{in}\NormalTok{ x\_points\_g, f }\KeywordTok{in}\NormalTok{ library]}

\CommentTok{\# llsq(library\_data, g\_sample\_points, bias = false) \# will error!}
\end{Highlighting}
\end{Shaded}

The above computation will result in an error on the \texttt{llsq}
calculation. The culprits are the functions \(\sin^2(x)\) and
\(\cos^2(x)\); they are linearly dependent due to
\(\sin^2(x) + \cos^2(x) = 1\). The net result is that the library data
matrix is ill-conditioned for basic least-squares. One might wonder why
we would include both \(\sin^2(x)\) and \(\cos^2(x)\) in the first
place. Here we should recall that the general problem is to find the
sparsest representation, i.e.~if we can use \(\cos^2(x)\) rather than
\(\sin^2(x) - 1\), this is preferable. One popular solution to the issue
of linearly dependent library data is \emph{ridge regression}
\cite{hoerl1970ridge} which introduces an additional parameter
\(\lambda\) and considers the optimization problem \begin{equation}
\xi^\star = \underset{\xi}{\text{argmin}}\bigg[ \lVert F - \Theta \xi \rVert_{2} + \lambda \lVert I \xi \rVert_{2} \bigg],
\end{equation} where \(I\) is the identity matrix. We can apply this
ridge regression with \(\lambda = 0.1\)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lambda\_ridge }\OperatorTok{=} \FloatTok{0.1}
\NormalTok{rr\_g }\OperatorTok{=} \FunctionTok{ridge}\NormalTok{(library\_data, g\_points, lambda\_ridge, bias }\OperatorTok{=} \ConstantTok{false}\NormalTok{) }\CommentTok{\# from MultivariateStats.jl}
\FunctionTok{g\_ridge}\NormalTok{(x) }\OperatorTok{=} \FunctionTok{sum}\NormalTok{(rr\_g[i]}\OperatorTok{*}\NormalTok{library[i](x) }\ControlFlowTok{for}\NormalTok{ i }\OperatorTok{=} \FloatTok{1}\OperatorTok{:}\FunctionTok{length}\NormalTok{(rr\_g))}

\NormalTok{g\_pred }\OperatorTok{=}\NormalTok{ library\_data }\OperatorTok{*}\NormalTok{ rr\_g}
\NormalTok{rmse }\OperatorTok{=} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{mean}\NormalTok{(}\FunctionTok{abs2}\NormalTok{.(g\_points }\OperatorTok{{-}}\NormalTok{ g\_pred)))}
\end{Highlighting}
\end{Shaded}

\begin{subequations} \label{eq:g-ridge} \scriptsize \begin{align}    g_{\text{ridge}}(x) &= 0.403 \cdot 1 + 1.01 \cdot x + 0.00129 \cdot x^{2} -0.000763 \cdot x^{3} + 0.929 \cdot \sin\left( x \right) + 0.00409 \cdot \cos\left( x \right) -0.307 \cdot \sin^{2}\left( x \right) + 0.71 \cdot \cos^{2}\left( x \right) \\
    \text{RMSE}[g_{\text{ridge}}] &= 0.0417 \end{align} \end{subequations}

We obtain a good fit as shown in Figure \ref{fig:g-ridge}, but it is not
sparse. With these motivating examples in hand, we can outline the
\emph{sequentially-thresholded ridge regression} (STRidge) algorithm.

\begin{tcolorbox}[enhanced jigsaw, colback=white, coltitle=black, rightrule=.15mm, opacitybacktitle=0.6, leftrule=.75mm, arc=.35mm, toprule=.15mm, breakable, opacityback=0, title={STRidge algorithm for sparse representation (Julia implementation)}, bottomtitle=1mm, toptitle=1mm, bottomrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, titlerule=0mm, colframe=quarto-callout-tip-color-frame, left=2mm]

\phantomsection\label{stridge}
\phantomsection\label{annotated-cell-13}%
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function} \FunctionTok{STRidge}\NormalTok{(}
\NormalTok{  target\_data}\OperatorTok{::}\DataTypeTok{Vector\{\textless{}:Real\}}\NormalTok{, }\hspace*{\fill}\NormalTok{\circled{1}}
\NormalTok{  library\_data}\OperatorTok{::}\DataTypeTok{Matrix\{\textless{}:Real\}}\NormalTok{; }\hspace*{\fill}\NormalTok{\circled{2}}
\NormalTok{  lambda\_sparse}\OperatorTok{::}\DataTypeTok{Real }\OperatorTok{=} \FloatTok{0.1}\NormalTok{, }\hspace*{\fill}\NormalTok{\circled{3}}
\NormalTok{  lambda\_ridge}\OperatorTok{::}\DataTypeTok{Real }\OperatorTok{=} \FloatTok{0.1}\NormalTok{, }\hspace*{\fill}\NormalTok{\circled{4}}
\NormalTok{  max\_iters}\OperatorTok{::}\DataTypeTok{Integer }\OperatorTok{=} \FloatTok{10}\NormalTok{)}

  \FunctionTok{rr}\NormalTok{(data) }\OperatorTok{=} \FunctionTok{ridge}\NormalTok{(data, target\_data, lambda\_ridge, bias }\OperatorTok{=} \ConstantTok{false}\NormalTok{) }\hspace*{\fill}\NormalTok{\circled{5}}
\NormalTok{  Xi }\OperatorTok{=} \FunctionTok{rr}\NormalTok{(library\_data)}

  \ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \FloatTok{1}\OperatorTok{:}\NormalTok{max\_iters}
\NormalTok{      smallinds }\OperatorTok{=} \FunctionTok{findall}\NormalTok{(p }\OperatorTok{{-}\textgreater{}} \FunctionTok{abs}\NormalTok{(p) }\OperatorTok{\textless{}}\NormalTok{ lambda\_sparse, Xi)}
\NormalTok{      Xi[smallinds] }\OperatorTok{.=} \FloatTok{0}
\NormalTok{      biginds }\OperatorTok{=} \FunctionTok{setdiff}\NormalTok{(}\FloatTok{1}\OperatorTok{:}\FunctionTok{length}\NormalTok{(Xi), smallinds)}
\NormalTok{      Xi[biginds] }\OperatorTok{=} \FunctionTok{rr}\NormalTok{(library\_data[}\OperatorTok{:}\NormalTok{, biginds])}
  \ControlFlowTok{end}

  \ControlFlowTok{return}\NormalTok{ Xi}
\KeywordTok{end}
\end{Highlighting}
\end{Shaded}

\begin{description}
\tightlist
\item[\circled{1}]
\texttt{target\_data} is a vector of function (observation) values of
length \(N\).
\item[\circled{2}]
\texttt{library\_data} is a matrix with a number of columns equal to the
number of library functions. Then, each column has \(N\) rows, one for
the library function evaluated at each observation.
\item[\circled{3}]
\texttt{lambda\_sparse} is the threshold below which library
coefficients are set equal to zero.
\item[\circled{4}]
\texttt{lambda\_ridge} is the ridge regression regularization parameter.
\item[\circled{5}]
\texttt{ridge} is an implementation the ridge regression algorithm from
\href{https://juliastats.org/MultivariateStats.jl/stable/lreg/\#Ridge-Regression}{\texttt{MultivariateStats.jl}}.
\end{description}

\end{tcolorbox}

We see that the core idea behind the \texttt{STRidge} function is simply
to iteratively threshold small library coefficients and ridge regress
the remaining library functions onto the target data. Let us apply this
to the \(g(x) = x + \sin(x) + \cos^2(x)\) case as above.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{g\_strr }\OperatorTok{=} \FunctionTok{STRidge}\NormalTok{(g\_points, library\_data, lambda\_sparse }\OperatorTok{=} \FloatTok{0.3}\NormalTok{, lambda\_ridge }\OperatorTok{=} \FloatTok{0.1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{subequations} \label{eq:g-strr} \begin{align}    g_{\text{strr}}(x) &= 1 \cdot x + 0.948 \cdot \sin\left( x \right) + 1.15 \cdot \cos^{2}\left( x \right) \\
    \text{RMSE}[g_{\text{strr}}] &= 0.0417 \end{align} \end{subequations}

Comparing Eq. \eqref{eq:g-strr} to \eqref{eq:g-ridge} shows that the
\texttt{STRidge} algorithm has resulted in a significantly more sparse
representation without increasing the rmse appreciably. Note that
\(\lambda_\text{sparse}\) and \(\lambda_\text{ridge}\) are not
prescribed currently. One has to choose their values judiciously to
simultaneously remove small terms and avoid removing large terms.

We will address one final issue before proceding to our discussion of
SINDy. What if the target data or observations are multidimensional? As
we are restricting our focus to dynamical systems, multidimensional
observations require no further calculation as all coordinates will be
functions of time. For example, a function such as
\(f(x, y) = x^2 + y^2\) can be sparely represented by using library
functions such as \(x(t), x^2(t) \dots, y(t), y^2(t), \dots\) which
amounts to increasing the number of columns in \(\Theta\). To handle
multidimensional observations, we simply apply the \texttt{STRidge}
algorithm to each dimension of the target data.

\begin{tcolorbox}[enhanced jigsaw, colback=white, coltitle=black, rightrule=.15mm, opacitybacktitle=0.6, leftrule=.75mm, arc=.35mm, toprule=.15mm, breakable, opacityback=0, title={STRidge algorithm extension to multidimensional observations (Julia
implementation)}, bottomtitle=1mm, toptitle=1mm, bottomrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, titlerule=0mm, colframe=quarto-callout-tip-color-frame, left=2mm]

\phantomsection\label{stridge-vec}
\phantomsection\label{annotated-cell-14}%
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function} \FunctionTok{STRidge}\NormalTok{(}
\NormalTok{  target\_data}\OperatorTok{::}\DataTypeTok{Matrix\{\textless{}:Real\}}\NormalTok{, }\hspace*{\fill}\NormalTok{\circled{1}}
\NormalTok{  library\_data}\OperatorTok{::}\DataTypeTok{Matrix\{\textless{}:Real\}}\NormalTok{; }
\NormalTok{  lambda\_sparse}\OperatorTok{::}\DataTypeTok{Real }\OperatorTok{=} \FloatTok{0.1}\NormalTok{,}
\NormalTok{  lambda\_ridge}\OperatorTok{::}\DataTypeTok{Real }\OperatorTok{=} \FloatTok{0.1}\NormalTok{,}
\NormalTok{  max\_iters}\OperatorTok{::}\DataTypeTok{Integer }\OperatorTok{=} \FloatTok{10}\NormalTok{)}

\NormalTok{    Xi }\OperatorTok{=} \FunctionTok{zeros}\NormalTok{(}\FunctionTok{size}\NormalTok{(library\_data, }\FloatTok{2}\NormalTok{), }\FunctionTok{size}\NormalTok{(target\_data, }\FloatTok{2}\NormalTok{))}
    \ControlFlowTok{for}\NormalTok{ i }\OperatorTok{=} \FloatTok{1}\OperatorTok{:}\FunctionTok{size}\NormalTok{(target\_data, }\FloatTok{2}\NormalTok{)}
\NormalTok{        sr }\OperatorTok{=} \FunctionTok{STRidge}\NormalTok{(target\_data[}\OperatorTok{:}\NormalTok{, i], library\_data, }
\NormalTok{            lambda\_sparse }\OperatorTok{=}\NormalTok{ lambda\_sparse, }
\NormalTok{            lambda\_ridge }\OperatorTok{=}\NormalTok{ lambda\_ridge,}
\NormalTok{            max\_iters }\OperatorTok{=}\NormalTok{ max\_iters) }\hspace*{\fill}\NormalTok{\circled{2}}
\NormalTok{        Xi[}\OperatorTok{:}\NormalTok{,i] }\OperatorTok{.=}\NormalTok{ sr}
    \ControlFlowTok{end}

    \ControlFlowTok{return}\NormalTok{ Xi}
\KeywordTok{end}
\end{Highlighting}
\end{Shaded}

\begin{description}
\tightlist
\item[\circled{1}]
\texttt{target\_data} is a now a matrix with \(N\) rows and a number of
columns equal to the dimension of the target.
\item[\circled{2}]
We call the scalar version of \texttt{STRidge} on each column of
\texttt{target\_data}.
\end{description}

\end{tcolorbox}

We will apply this to multidimensional target data using our \(f(x)\)
and \(g(x)\) functions of Figure \ref{fig:sparse-motivation}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{target\_data }\OperatorTok{=}\NormalTok{ [f\_simple\_points ;; g\_points]}
\NormalTok{fg\_strr }\OperatorTok{=} \FunctionTok{STRidge}\NormalTok{(target\_data, library\_data, lambda\_sparse }\OperatorTok{=} \FloatTok{0.3}\NormalTok{, lambda\_ridge }\OperatorTok{=} \FloatTok{0.1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{subequations} \label{eq:g-strr} \begin{align}    f_{\text{strr}}(x) &= 1 \cdot x + 0.948 \cdot \sin\left( x \right) \\
  g_{\text{strr}}(x) &= 1 \cdot x + 0.948 \cdot \sin\left( x \right) + 1.15 \cdot \cos^{2}\left( x \right) \end{align} \end{subequations}

These are the correct sparse representations.

\subsection{SINDy}\label{sindy}

We will now outline the procedure required to apply the sparse
representation algorithms discussed previously to dynamical systems.
First, we assume that we have systems of the form
\begin{equation} \label{eq:ode-general}
\frac{\text{d}^n X}{\text{d}t^n} = f(t, X,  X', X'', \dots, X^{(n - 1)}),
\end{equation} where \(X(t) = (x(y), y(t), z(t),  \dots))\) is a vector
of coordinates and \(f\), can be represented by sparse linear
combinations of elementary functions. We also assume that the data we
have access to are trajectory observations
\(\{X(t_1), X(t_2), \dots \}\). Eq. \eqref{eq:ode-general} can be
readily represented as a system of first order differential equations
where all of the nontrivial dynamics are contained in \(f\). If we had
access to \(\{\dot{X}(t_1), \dot{X}(t_2), \dots \}\) and higher
derivatives, then this would immediately result in a sparse
representation problem for the function \(f\). Hence, we only need one
preprocessing function \texttt{derivatives} outlined below which will
provide the required derivatives via spline interpolation.

\begin{tcolorbox}[enhanced jigsaw, colback=white, coltitle=black, rightrule=.15mm, opacitybacktitle=0.6, leftrule=.75mm, arc=.35mm, toprule=.15mm, breakable, opacityback=0, title={Compute derivatives of a trajectory (Julia implementation)}, bottomtitle=1mm, toptitle=1mm, bottomrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, titlerule=0mm, colframe=quarto-callout-tip-color-frame, left=2mm]

\phantomsection\label{annotated-cell-15}%
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function} \FunctionTok{derivatives}\NormalTok{(}
\NormalTok{  times}\OperatorTok{::}\DataTypeTok{Vector\{\textless{}:Real\}}\NormalTok{, }\hspace*{\fill}\NormalTok{\circled{1}}
\NormalTok{  trajectories}\OperatorTok{::}\DataTypeTok{Matrix\{\textless{}:Real\}}\NormalTok{; }\hspace*{\fill}\NormalTok{\circled{2}}
\NormalTok{  derivative\_order}\OperatorTok{::}\DataTypeTok{Integer }\OperatorTok{=} \FloatTok{1}\NormalTok{,}
\NormalTok{  spline\_order}\OperatorTok{::}\DataTypeTok{Integer }\OperatorTok{=} \FunctionTok{max}\NormalTok{(derivative\_order }\OperatorTok{+} \FloatTok{1}\NormalTok{, }\FloatTok{4}\NormalTok{)) }\hspace*{\fill}\NormalTok{\circled{3}}

\NormalTok{  bo }\OperatorTok{=} \FunctionTok{BSplineOrder}\NormalTok{(spline\_order)}
\NormalTok{  bn }\OperatorTok{=}\NormalTok{ BSplineKit.}\FunctionTok{Natural}\NormalTok{()}

\NormalTok{  itps }\OperatorTok{=}\NormalTok{ [}\FunctionTok{spline}\NormalTok{(}\FunctionTok{interpolate}\NormalTok{(times, trajectories[}\OperatorTok{:}\NormalTok{,i], bo, bn)) }\hspace*{\fill}\NormalTok{\circled{4}}
\NormalTok{    for i }\OperatorTok{=} \FloatTok{1}\OperatorTok{:}\FunctionTok{size}\NormalTok{(trajectories, }\FloatTok{2}\NormalTok{)]}

\NormalTok{  data }\OperatorTok{=}\NormalTok{ [[}\FunctionTok{diff}\NormalTok{(S, }\FunctionTok{Derivative}\NormalTok{(i))(t) for t }\KeywordTok{in}\NormalTok{ times, S }\KeywordTok{in}\NormalTok{ itps] }\hspace*{\fill}\NormalTok{\circled{5}}
\NormalTok{    for i }\OperatorTok{=} \FloatTok{0}\OperatorTok{:}\NormalTok{derivative\_order]}

  \ControlFlowTok{return}\NormalTok{ data}
\KeywordTok{end}
\end{Highlighting}
\end{Shaded}

\begin{description}
\tightlist
\item[\circled{1}]
\texttt{times} is a vector of times that the trajectory data are given
on of length \(N\).
\item[\circled{2}]
\texttt{trajectories} is a matrix with \(N\) rows and a number of
columns equal to the number of coordinates.
\item[\circled{3}]
Spline order of 4 corresponds to cubic splines.
\item[\circled{4}]
Spline interpolation using
\href{https://jipolanco.github.io/BSplineKit.jl/stable/}{BSplineKit.jl}.
\item[\circled{5}]
Construct and return a vector of matrices, where
\texttt{data{[}i{]}{[}:,j{]}} is the \texttt{(i-1)}th derivative of the
\texttt{j}th coordinate evaluated at \texttt{times}. Note that the
\texttt{0}th derivative is the coordinate itself.
\end{description}

\end{tcolorbox}

We can therefore treat the data generated by \texttt{derivatives} as the
\texttt{target\_data} for our sparse representation algorithm; this is
precisely the standard SINDy algorithm which we may now describe in
pseudocode.

\begin{tcolorbox}[enhanced jigsaw, colback=white, coltitle=black, rightrule=.15mm, opacitybacktitle=0.6, leftrule=.75mm, arc=.35mm, toprule=.15mm, breakable, opacityback=0, title={SINDy {[}standard{]}}, bottomtitle=1mm, toptitle=1mm, bottomrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, titlerule=0mm, colframe=quarto-callout-tip-color-frame, left=2mm]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Let \(X\) be an \(N \times v\) matrix where the \(i^\text{th}\) row is
  an observation of \(v\) variables at time \(t_i\). We assume that
  \(X\) satisfies an \(n^\text{th}\) order ODE of the form Eq.
  \eqref{eq:ode-general}.
\item
  Compute \texttt{D\ =\ derivatives(t,\ X,\ derivative\_order\ =\ n)}.
  The last entry of \texttt{D} is an \(N \times v\) matrix of
  \(\text{d}X^n/\text{d}t^n\) values, which is the
  \texttt{target\_data}.
\item
  Construct \texttt{library\_data} containing the proposed functions to
  include in the sparse representation. This is a matrix with \(N\) rows
  and an arbirary number of columns. Each column is in principle any
  function of \(t\) evaluated at each time. Usually the most appropriate
  functions of \(t\) will be functions of the coordinates \(v(t)\). Note
  that entries of \texttt{D} other than the last one are derivatives of
  order up to \(n - 1\) of \(X\) and any function of these may also
  appear in \texttt{library\_data}.
\item
  Compute
  \texttt{Xi\ =\ STRidge(target\_data,\ library\_data;\ lambda\_sparse,\ lambda\_ridge)},
  where \texttt{lambda\_sparse} should be chosen small enough to
  sparsify the representation but large enough to faithfully represent
  \(X\). The final sparse representation is given by multiplying
  \texttt{Xi} by the library functions.
\end{enumerate}

\end{tcolorbox}

The most common library functions are polynomials, but it is cumbersome
to create lists of every possible multivariable monomial by hand. We
therefore automate this process using the \texttt{polynomials} function
below. Note that this is not necessarily part of the core SINDy
algorithm, it is simply a convenience.

\begin{tcolorbox}[enhanced jigsaw, colback=white, coltitle=black, rightrule=.15mm, opacitybacktitle=0.6, leftrule=.75mm, arc=.35mm, toprule=.15mm, breakable, opacityback=0, title={Compute arbitrary polynomial functions of variables (Julia
implementation)}, bottomtitle=1mm, toptitle=1mm, bottomrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, titlerule=0mm, colframe=quarto-callout-tip-color-frame, left=2mm]

\phantomsection\label{annotated-cell-16}%
\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function} \FunctionTok{polynomials}\NormalTok{(}
\NormalTok{  data}\OperatorTok{::}\DataTypeTok{Matrix\{\textless{}:Real\}}\NormalTok{, }\hspace*{\fill}\NormalTok{\circled{1}}
\NormalTok{  order}\OperatorTok{::}\DataTypeTok{Integer}\NormalTok{; }\hspace*{\fill}\NormalTok{\circled{2}}
\NormalTok{  var\_names}\OperatorTok{::}\DataTypeTok{Union\{Vector\{\textless{}:String\}, Nothing\} }\OperatorTok{=} \ConstantTok{nothing}\NormalTok{) }\hspace*{\fill}\NormalTok{\circled{3}}

\NormalTok{  var\_names }\OperatorTok{=}\NormalTok{ var\_names }\OperatorTok{===} \ConstantTok{nothing}\NormalTok{ ? [}\StringTok{"x}\SpecialCharTok{$}\NormalTok{(i)}\StringTok{"}\NormalTok{ for i }\OperatorTok{=} \FloatTok{1}\OperatorTok{:}\FunctionTok{size}\NormalTok{(data, }\FloatTok{2}\NormalTok{)] }\OperatorTok{:}\NormalTok{ var\_names}
\NormalTok{  exps }\OperatorTok{=}\NormalTok{ [}\FunctionTok{multiexponents}\NormalTok{(}\FunctionTok{size}\NormalTok{(data, }\FloatTok{2}\NormalTok{), i) for i }\OperatorTok{=} \FloatTok{0}\OperatorTok{:}\NormalTok{order] }\hspace*{\fill}\NormalTok{\circled{4}}

\NormalTok{  polys }\OperatorTok{=} \FunctionTok{zeros}\NormalTok{(}\FunctionTok{size}\NormalTok{(data, }\FloatTok{1}\NormalTok{), }\FunctionTok{sum}\NormalTok{(}\FunctionTok{length}\NormalTok{.(exps)))}
\NormalTok{  names }\OperatorTok{=} \FunctionTok{fill}\NormalTok{(}\StringTok{""}\NormalTok{, }\FunctionTok{size}\NormalTok{(polys, }\FloatTok{2}\NormalTok{))}

\NormalTok{  polys\_i }\OperatorTok{=} \FloatTok{1}
  \ControlFlowTok{for}\NormalTok{ order }\KeywordTok{in}\NormalTok{ exps, ex }\KeywordTok{in}\NormalTok{ order}
\NormalTok{    polys[}\OperatorTok{:}\NormalTok{,polys\_i] }\OperatorTok{.=}\NormalTok{ [data[}\OperatorTok{:}\NormalTok{,i] }\OperatorTok{.\^{}}\NormalTok{ ex[i] for i }\OperatorTok{=} \FloatTok{1}\OperatorTok{:}\FunctionTok{size}\NormalTok{(data, }\FloatTok{2}\NormalTok{)] }\OperatorTok{|\textgreater{}} 
\NormalTok{      x }\OperatorTok{{-}\textgreater{}} \FunctionTok{prod}\NormalTok{(}\FunctionTok{stack}\NormalTok{(x), dims }\OperatorTok{=} \FloatTok{2}\NormalTok{) }\hspace*{\fill}\NormalTok{\circled{5}}

\NormalTok{    name }\OperatorTok{=} \StringTok{""} 
    \ControlFlowTok{for}\NormalTok{ i }\OperatorTok{=} \FloatTok{1}\OperatorTok{:}\FunctionTok{length}\NormalTok{(var\_names) }
      \ControlFlowTok{if}\NormalTok{ ex[i] }\OperatorTok{!=} \FloatTok{0} 
\NormalTok{        name }\OperatorTok{*=}\NormalTok{ var\_names[i] }\OperatorTok{*}\NormalTok{ (ex[i] }\OperatorTok{!=} \FloatTok{1}\NormalTok{ ? }\StringTok{"\^{}}\SpecialCharTok{$}\NormalTok{(ex[i])}\StringTok{"} \OperatorTok{:} \StringTok{""}\NormalTok{) }\hspace*{\fill}\NormalTok{\circled{6}}
      \ControlFlowTok{end}
    \ControlFlowTok{end}
\NormalTok{    names[polys\_i] }\OperatorTok{=}\NormalTok{ name}
\NormalTok{    polys\_i }\OperatorTok{+=} \FloatTok{1}
  \ControlFlowTok{end}

\NormalTok{  names[}\FloatTok{1}\NormalTok{] }\OperatorTok{=} \StringTok{"1"}

  \ControlFlowTok{return}\NormalTok{ (polys, names)}
\KeywordTok{end}
\end{Highlighting}
\end{Shaded}

\begin{description}
\tightlist
\item[\circled{1}]
\texttt{data} is a matrix with \(N\) rows and a number of columns equal
to the number of variables.
\item[\circled{2}]
\texttt{order} is an integer equal to the maximum monomial order
requested, e.g.~if \texttt{order\ ==\ 2} with two variables
\texttt{x,\ y}, then \texttt{polynomials} will compute
\texttt{1,\ x,\ y,\ x\^{}2,\ y\^{}2,\ xy}.
\item[\circled{3}]
If provided, \texttt{var\_names} will assign the given names to each
variable in its output. Otherwise, defaults \texttt{x1,\ x2,\ ...} will
be used.
\item[\circled{4}]
Multiexponents using
\href{https://juliamath.github.io/Combinatorics.jl/dev/}{Combinatorics.jl}.
\item[\circled{5}]
Compute each monomial term by raising each column to the appropriate
exponent, and then multiply all columns.
\item[\circled{6}]
If an exponent is zero, we don't want its name to show uup in that term,
and if an exponent is 1, we omit the exponent. Otherwise, the exponent
is shown.
\end{description}

\end{tcolorbox}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data }\OperatorTok{=} \FunctionTok{rand}\NormalTok{(}\FloatTok{3}\NormalTok{,  }\FloatTok{2}\NormalTok{) }\CommentTok{\# 3 times, 2 variables}
\NormalTok{order }\OperatorTok{=} \FloatTok{2} \CommentTok{\# all monomials up to and including 2}

\NormalTok{ps }\OperatorTok{=} \FunctionTok{polynomials}\NormalTok{(data, order, var\_names }\OperatorTok{=}\NormalTok{ [}\StringTok{"x"}\NormalTok{, }\StringTok{"y"}\NormalTok{])}
\PreprocessorTok{@info}\NormalTok{ ps[}\FloatTok{2}\NormalTok{]}
\FunctionTok{round}\NormalTok{.(ps[}\FloatTok{1}\NormalTok{], sigdigits }\OperatorTok{=} \FloatTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[ Info: ["1", "x", "y", "x^2", "xy", "y^2"]
\end{verbatim}

\begin{verbatim}
3×6 Matrix{Float64}:
 1.0  0.42   0.535  0.177  0.225  0.286
 1.0  0.46   0.942  0.212  0.433  0.886
 1.0  0.457  0.251  0.209  0.115  0.063
\end{verbatim}

\clearpage

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function} \FunctionTok{lorenz!}\NormalTok{(du, u, p, t)}
\NormalTok{    x, y, z }\OperatorTok{=}\NormalTok{ u}
\NormalTok{    du[}\FloatTok{1}\NormalTok{] }\OperatorTok{=} \FloatTok{10.0} \OperatorTok{*}\NormalTok{ (y }\OperatorTok{{-}}\NormalTok{ x)}
\NormalTok{    du[}\FloatTok{2}\NormalTok{] }\OperatorTok{=}\NormalTok{ x }\OperatorTok{*}\NormalTok{ (}\FloatTok{28.0} \OperatorTok{{-}}\NormalTok{ z) }\OperatorTok{{-}}\NormalTok{ y}
\NormalTok{    du[}\FloatTok{3}\NormalTok{] }\OperatorTok{=}\NormalTok{ x }\OperatorTok{*}\NormalTok{ y }\OperatorTok{{-}}\NormalTok{ (}\FloatTok{8} \OperatorTok{/} \FloatTok{3}\NormalTok{) }\OperatorTok{*}\NormalTok{ z}
\KeywordTok{end}

\NormalTok{sol\_lorenz }\OperatorTok{=} \FunctionTok{ODEProblem}\NormalTok{(lorenz!, [}\FloatTok{1.0}\NormalTok{, }\FloatTok{1.0}\NormalTok{, }\FloatTok{1.0}\NormalTok{], (}\FloatTok{0.0}\NormalTok{, }\FloatTok{10.0}\NormalTok{)) }\OperatorTok{|\textgreater{}}\NormalTok{ solve}

\NormalTok{times\_lorenz }\OperatorTok{=} \FunctionTok{range}\NormalTok{(}\FloatTok{0.0}\NormalTok{, }\FloatTok{10.0}\NormalTok{, length }\OperatorTok{=} \FloatTok{1000}\NormalTok{) }\OperatorTok{|\textgreater{}}\NormalTok{ collect}
\NormalTok{traj\_lorenz }\OperatorTok{=}\NormalTok{ [}\FunctionTok{sol\_lorenz}\NormalTok{(t)[i] for t }\KeywordTok{in}\NormalTok{ times\_lorenz, i }\OperatorTok{=} \FloatTok{1}\OperatorTok{:}\FloatTok{3}\NormalTok{]}

\NormalTok{ds }\OperatorTok{=} \FunctionTok{derivatives}\NormalTok{(times\_lorenz, traj\_lorenz, derivative\_order }\OperatorTok{=} \FloatTok{1}\NormalTok{)}
\NormalTok{x\_L, dx\_L }\OperatorTok{=}\NormalTok{ ds[}\FloatTok{1}\NormalTok{][}\OperatorTok{:}\NormalTok{,}\FloatTok{1}\NormalTok{], ds[}\FloatTok{2}\NormalTok{][}\OperatorTok{:}\NormalTok{,}\FloatTok{1}\NormalTok{]}
\NormalTok{y\_L, dy\_L }\OperatorTok{=}\NormalTok{ ds[}\FloatTok{1}\NormalTok{][}\OperatorTok{:}\NormalTok{,}\FloatTok{2}\NormalTok{], ds[}\FloatTok{2}\NormalTok{][}\OperatorTok{:}\NormalTok{,}\FloatTok{2}\NormalTok{]}
\NormalTok{z\_L, dz\_L }\OperatorTok{=}\NormalTok{ ds[}\FloatTok{1}\NormalTok{][}\OperatorTok{:}\NormalTok{,}\FloatTok{3}\NormalTok{], ds[}\FloatTok{2}\NormalTok{][}\OperatorTok{:}\NormalTok{,}\FloatTok{3}\NormalTok{]}

\NormalTok{target\_data }\OperatorTok{=}\NormalTok{ [dx\_L ;; dy\_L ;; dz\_L]}
\NormalTok{library\_data, library\_names }\OperatorTok{=} \FunctionTok{polynomials}\NormalTok{(traj\_lorenz, }\FloatTok{3}\NormalTok{, var\_names }\OperatorTok{=}\NormalTok{ [}\StringTok{"x"}\NormalTok{, }\StringTok{"y"}\NormalTok{, }\StringTok{"z"}\NormalTok{])}

\NormalTok{rr }\OperatorTok{=} \FunctionTok{STRidge}\NormalTok{(target\_data, library\_data, lambda\_sparse }\OperatorTok{=} \FloatTok{0.3}\NormalTok{)}
\FunctionTok{pretty\_print}\NormalTok{(rr, library\_names)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
3-element Vector{String}:
 "-10.0*x + 10.0*y"
 "28.0*x + -0.986*y + -0.999*xz"
 "-2.67*z + 0.999*xy"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{points }\OperatorTok{=}\NormalTok{ []}
\NormalTok{rrs }\OperatorTok{=}\NormalTok{ []}
\NormalTok{n\_terms\_poss }\OperatorTok{=}\NormalTok{ []}
\ControlFlowTok{for}\NormalTok{ lambda\_sparse }\KeywordTok{in} \FloatTok{10} \OperatorTok{.\^{}} \FunctionTok{range}\NormalTok{(}\OperatorTok{{-}}\FloatTok{3}\NormalTok{, }\FloatTok{1}\NormalTok{, length }\OperatorTok{=} \FloatTok{1000}\NormalTok{)}
\NormalTok{  rr }\OperatorTok{=} \FunctionTok{STRidge}\NormalTok{(target\_data, library\_data, lambda\_sparse }\OperatorTok{=}\NormalTok{ lambda\_sparse, lambda\_ridge }\OperatorTok{=} \FloatTok{0.1}\NormalTok{)}
\NormalTok{  rmse }\OperatorTok{=} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{mean}\NormalTok{(}\FunctionTok{abs2}\NormalTok{.(target\_data }\OperatorTok{{-}}\NormalTok{ library\_data }\OperatorTok{*}\NormalTok{ rr)))}
\NormalTok{  n\_terms }\OperatorTok{=} \FunctionTok{count}\NormalTok{(iszero, rr)}

  \ControlFlowTok{if}\NormalTok{ !(n\_terms }\KeywordTok{in}\NormalTok{ n\_terms\_poss)}
    \FunctionTok{push!}\NormalTok{(points, [lambda\_sparse, n\_terms, rmse])}
    \FunctionTok{push!}\NormalTok{(rrs, rr)}
    \FunctionTok{push!}\NormalTok{(n\_terms\_poss, n\_terms)}
  \ControlFlowTok{else}
\NormalTok{    points[}\KeywordTok{end}\NormalTok{] }\OperatorTok{=}\NormalTok{ [lambda\_sparse, n\_terms, rmse]}
\NormalTok{    rrs[}\KeywordTok{end}\NormalTok{] }\OperatorTok{=}\NormalTok{ rr}
  \ControlFlowTok{end}
\ControlFlowTok{end}
\NormalTok{points }\OperatorTok{=} \FunctionTok{stack}\NormalTok{(points, dims }\OperatorTok{=} \FloatTok{1}\NormalTok{)}
\FunctionTok{scatter}\NormalTok{(}\FunctionTok{log10}\NormalTok{.(points[}\OperatorTok{:}\NormalTok{,}\FloatTok{1}\NormalTok{]), points[}\OperatorTok{:}\NormalTok{,}\FloatTok{3}\NormalTok{], color }\OperatorTok{=}\NormalTok{ points[}\OperatorTok{:}\NormalTok{,}\FloatTok{2}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\includegraphics{test_files/figure-pdf/cell-25-output-1.png}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n\_bootstraps }\OperatorTok{=} \FloatTok{1000}
\NormalTok{lambda\_sparse }\OperatorTok{=} \FloatTok{0.8}
\NormalTok{lambda\_ridge }\OperatorTok{=} \FloatTok{0.0}
\NormalTok{max\_iters }\OperatorTok{=} \FloatTok{10}

\NormalTok{Xi }\OperatorTok{=} \FunctionTok{zeros}\NormalTok{(}\FunctionTok{size}\NormalTok{(library\_data, }\FloatTok{2}\NormalTok{), }\FunctionTok{size}\NormalTok{(target\_data, }\FloatTok{2}\NormalTok{), n\_bootstraps)}
\ControlFlowTok{for}\NormalTok{ b }\OperatorTok{=} \FloatTok{1}\OperatorTok{:}\NormalTok{n\_bootstraps}
\NormalTok{    idx }\OperatorTok{=} \FunctionTok{sample}\NormalTok{(}\FloatTok{1}\OperatorTok{:}\FunctionTok{length}\NormalTok{(times\_lorenz), }\FunctionTok{length}\NormalTok{(times\_lorenz), replace }\OperatorTok{=} \ConstantTok{true}\NormalTok{)}
\NormalTok{    Xi\_b }\OperatorTok{=} \FunctionTok{STRidge}\NormalTok{(target\_data[idx,}\OperatorTok{:}\NormalTok{], library\_data[idx,}\OperatorTok{:}\NormalTok{], }
\NormalTok{        lambda\_sparse }\OperatorTok{=}\NormalTok{ lambda\_sparse,}
\NormalTok{        lambda\_ridge }\OperatorTok{=}\NormalTok{ lambda\_ridge,}
\NormalTok{        max\_iters }\OperatorTok{=}\NormalTok{ max\_iters)}

\NormalTok{    Xi[}\OperatorTok{:}\NormalTok{,}\OperatorTok{:}\NormalTok{,b] }\OperatorTok{.=}\NormalTok{ Xi\_b}
\ControlFlowTok{end}

\NormalTok{ip }\OperatorTok{=} \FunctionTok{mean}\NormalTok{(}\FunctionTok{map}\NormalTok{(x }\OperatorTok{{-}\textgreater{}}\NormalTok{ x }\OperatorTok{!=} \FloatTok{0}\NormalTok{ ? }\FloatTok{1.0} \OperatorTok{:} \FloatTok{0.0}\NormalTok{, Xi), dims }\OperatorTok{=} \FloatTok{3}\NormalTok{)[}\OperatorTok{:}\NormalTok{,}\OperatorTok{:}\NormalTok{,}\FloatTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
20×3 Matrix{Float64}:
 0.0  0.478  0.001
 1.0  0.898  0.0
 1.0  0.131  0.001
 0.0  0.159  0.999
 0.0  0.0    0.0
 0.0  0.0    0.999
 0.0  0.145  0.0
 0.0  0.0    0.0
 0.0  0.0    0.0
 0.0  0.0    0.0
 0.0  0.0    0.0
 0.0  0.0    0.0
 0.0  0.0    0.0
 0.0  0.0    0.0
 0.0  0.0    0.0
 0.0  0.0    0.0
 0.0  0.0    0.0
 0.0  0.0    0.0
 0.0  0.0    0.0
 0.0  0.0    0.0
\end{verbatim}

\subsection{E-SINDy}\label{e-sindy}

\section{Julia Implementation}\label{julia-implementation}

\section{Results}\label{results}

\subsection{Direct sparse
representations}\label{direct-sparse-representations}

\subsection{Fluid}\label{fluid}

\subsection{Slow}\label{slow}

\subsection{Full}\label{full}

\section{Conclusions}\label{conclusions}


\printbibliography


\end{document}
